{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Dependencies and Setting Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set hyperparameters\n",
    "max_len = 40\n",
    "step = 2\n",
    "num_hiddens = 128 #no. of layers in LSTM\n",
    "learning_rate = 0.01\n",
    "batch_size = 200\n",
    "epoch = 6 #set low for low computation cost\n",
    "temperature = 0.5 #to control the randomness of predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Helper Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    '''\n",
    "     open and read text file\n",
    "    '''\n",
    "    text = open(file_name, 'r').read()\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4573338"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Length of text corpus\n",
    "len(read_data('shakespeare_input.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting subset from text corpus\n",
    "data=read_data('shakespeare_input.txt')[:573338]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(text):\n",
    "    '''\n",
    "     featurize the text to train and target dataset\n",
    "    '''\n",
    "    unique_chars = list(set(text))\n",
    "    len_unique_chars = len(unique_chars)\n",
    "\n",
    "    input_chars = []\n",
    "    output_char = []\n",
    "\n",
    "    for i in range(0, len(text) - max_len, step):\n",
    "        input_chars.append(text[i:i+max_len])\n",
    "        output_char.append(text[i+max_len])\n",
    "\n",
    "    train_data = np.zeros((len(input_chars), max_len, len_unique_chars))\n",
    "    target_data = np.zeros((len(input_chars), len_unique_chars))\n",
    "\n",
    "    for i , each in enumerate(input_chars):\n",
    "        for j, char in enumerate(each):\n",
    "            train_data[i, j, unique_chars.index(char)] = 1\n",
    "        target_data[i, unique_chars.index(output_char[i])] = 1\n",
    "    return train_data, target_data, unique_chars, len_unique_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(x, weight, bias, len_unique_chars):\n",
    "    '''\n",
    "     define rnn cell and prediction\n",
    "    '''\n",
    "    x = tf.transpose(x, [1, 0, 2])\n",
    "    x = tf.reshape(x, [-1, len_unique_chars])\n",
    "    x = tf.split(x, max_len, 0)\n",
    "\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_hiddens, forget_bias=1.0)\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(cell, x, dtype=tf.float32)\n",
    "    prediction = tf.matmul(outputs[-1], weight) + bias\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(predicted):\n",
    "    '''\n",
    "     helper function to sample an index from a probability array\n",
    "    '''\n",
    "    exp_predicted = np.exp(predicted/temperature) #Scaling logits\n",
    "    predicted = exp_predicted / np.sum(exp_predicted)\n",
    "    probabilities = np.random.multinomial(1, predicted, 1)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(train_data, target_data, unique_chars, len_unique_chars):\n",
    "    '''\n",
    "     main run function\n",
    "    '''\n",
    "    #Initializing Parameters\n",
    "    x = tf.placeholder(\"float\", [None, max_len, len_unique_chars])\n",
    "    y = tf.placeholder(\"float\", [None, len_unique_chars])\n",
    "    weight = tf.Variable(tf.random_normal([num_hiddens, len_unique_chars]))\n",
    "    bias = tf.Variable(tf.random_normal([len_unique_chars]))\n",
    "    \n",
    "    #Model Cost Reduction,Weights Optimization and Prediction\n",
    "    prediction = rnn(x, weight, bias, len_unique_chars)\n",
    "    softmax = tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y)\n",
    "    cost = tf.reduce_mean(softmax)\n",
    "    optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init_op)\n",
    "\n",
    "    num_batches = int(len(train_data)/batch_size)\n",
    "\n",
    "    for i in range(epoch):\n",
    "        print (\"----------- Epoch {0}/{1} -----------\".format(i+1, epoch))\n",
    "        count = 0\n",
    "        for _ in range(num_batches):\n",
    "            train_batch, target_batch = train_data[count:count+batch_size], target_data[count:count+batch_size]\n",
    "            count += batch_size\n",
    "            sess.run([optimizer] ,feed_dict={x:train_batch, y:target_batch})\n",
    "\n",
    "        #get on of training set as seed\n",
    "        seed = train_batch[:1:]\n",
    "\n",
    "        #to print the seed 40 characters\n",
    "        seed_chars = ''\n",
    "        for each in seed[0]:\n",
    "                seed_chars += unique_chars[np.where(each == max(each))[0][0]]\n",
    "        print( \"Seed:\", seed_chars)\n",
    "\n",
    "        #predict next 1000 characters\n",
    "        for i in range(1000):\n",
    "            if i > 0:\n",
    "                remove_fist_char = seed[:,1:,:]\n",
    "                seed = np.append(remove_fist_char, np.reshape(probabilities, [1, 1, len_unique_chars]), axis=1)\n",
    "            predicted = sess.run([prediction], feed_dict = {x:seed})\n",
    "            predicted = np.asarray(predicted[0]).astype('float64')[0]\n",
    "            probabilities = sample(predicted)\n",
    "            predicted_chars = unique_chars[np.argmax(probabilities)]\n",
    "            seed_chars += predicted_chars\n",
    "        print ('Result:', seed_chars)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sanjay/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-7-647332350d55>:9: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-7-647332350d55>:10: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From <ipython-input-9-9abcaba89040>:11: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "----------- Epoch 1/6 -----------\n",
      "Seed: condemned and myself excused.\n",
      "\n",
      "prince:\n",
      "t\n",
      "Result: condemned and myself excused.\n",
      "\n",
      "prince:\n",
      "then these here with thou these and weets:\n",
      "go dead the langer dead, and what at gone be the death,\n",
      "will and will breath, many i day some these to-morrow of butter,\n",
      "to them there be heaven and woentous forth for the fach the more hath a death,\n",
      "what is my longer us to my bead\n",
      "with here then, with his no is the dead,\n",
      "and so so more these my lies white the blood,\n",
      "and with the dide the satch so be that wath.\n",
      "this dead the place is the grief and there be this aman to exclemples and meldeath\n",
      "and of mishing the prouder him lood and the sund's my elfe\n",
      "and speak the worth my is that with at in thee the part'd these.\n",
      "\n",
      "prince:\n",
      "i will with musteriagh and from thee the proous arm reman\n",
      "and was to be be you wear thee a doth mesthere\n",
      "and the prown hath to the borom, and here?\n",
      "\n",
      "prince:\n",
      "what some this shall he words thee, and to chart to bleasty.\n",
      "\n",
      "prince:\n",
      "all head day these the lady the death to chasted\n",
      "to thy father this death my look to juliet and the morth,\n",
      "and seech me me to the doward that my death.\n",
      "----------- Epoch 2/6 -----------\n",
      "Seed: condemned and myself excused.\n",
      "\n",
      "prince:\n",
      "t\n",
      "Result: condemned and myself excused.\n",
      "\n",
      "prince:\n",
      "the king mercuness and here is moon these long.\n",
      "\n",
      "first not than and cannot thee,\n",
      "it world to seet them is the great thee die,\n",
      "wift a fare the tears, the doth a ready,\n",
      "or lord and that woe, and here dead the torm\n",
      "and woms to the streng of the word, and holy state.\n",
      "\n",
      "friar laurence:\n",
      "are from the wasle forth, and but love these faith,\n",
      "and then a clack to the faith, and so sill.\n",
      "\n",
      "friar laurence:\n",
      "where is me to the manured and this wearth.\n",
      "\n",
      "friar laurence:\n",
      "i world the king the cousin thee, and come,\n",
      "and at these forth, can to been a to beath,\n",
      "that earth, and there be thee word and should not at nurse,\n",
      "and death?\n",
      "\n",
      "second is that that with the chorge.\n",
      "\n",
      "friar laurence:\n",
      "and with a chillor, and fleal me words,\n",
      "with my nights as i fall thy back,\n",
      "and with this meach and in the tears and in the world.\n",
      "\n",
      "peter:\n",
      "what says whom the death doth not not to bury:\n",
      "as what shall be scome to mercimes the day,\n",
      "and fair the kingers hath light to the stirs\n",
      "and all the death, the capule is a death\n",
      "and not and send \n",
      "----------- Epoch 3/6 -----------\n",
      "Seed: condemned and myself excused.\n",
      "\n",
      "prince:\n",
      "t\n",
      "Result: condemned and myself excused.\n",
      "\n",
      "prince:\n",
      "then a montague, let me bride is the mother\n",
      "and some not to bear here and be come of thee.\n",
      "\n",
      "nurse:\n",
      "then the mother doth and remas letters,\n",
      "and here am the street me some their country\n",
      "is this hate and some is paris are the comments and fleart me loes.\n",
      "\n",
      "romeo:\n",
      "i see, and my long watch of death we sight.\n",
      "\n",
      "friar laurence:\n",
      "what says thee the sels, and sturrs and the death\n",
      "that the tongue to the some to thy dead!\n",
      "how now, and great it the long the world.\n",
      "\n",
      "prince:\n",
      "i will do you so this long and death,\n",
      "and i saw the mother wom for the death,\n",
      "and then the earth, we to cheep thee hours\n",
      "and see is out for this fathing the cormont\n",
      "a romeo with him of this death and bridage,\n",
      "and there will have is the heart be solan\n",
      "some these forth haste the common the dead?\n",
      "\n",
      "lady capulet:\n",
      "what death here will will was thou stay man,\n",
      "and there is the romeo, there as i will the world's tormother,\n",
      "and women is than i be montague, here is a word,\n",
      "and thou art a father, i did manture many talis\n",
      "do mouther to romeo! wh\n",
      "----------- Epoch 4/6 -----------\n",
      "Seed: condemned and myself excused.\n",
      "\n",
      "prince:\n",
      "t\n",
      "Result: condemned and myself excused.\n",
      "\n",
      "prince:\n",
      "then a gone of this son to to the death\n",
      "in the honourable of the moaths as death\n",
      "buried but so this romeo for the light,\n",
      "i hearty shall be romeo with this all amen.\n",
      "\n",
      "romeo:\n",
      "what say they sleep dies'd thee, there is death,\n",
      "to many heaven there for the face with thee.\n",
      "\n",
      "friar laurence:\n",
      "here lies the wide and speak here with the montague;\n",
      "and you will hear her lady these will be soul\n",
      "of in thy brows and with him the honour lies\n",
      "which the prince of this shouldst of the montague.\n",
      "\n",
      "friar laurence:\n",
      "my lord, i say, the torming the dead, be stay.\n",
      "\n",
      "friar laurence:\n",
      "i will say the boy! here is not to speak.\n",
      "\n",
      "friar laurence:\n",
      "then thou can thy poor not so this now with thy words.\n",
      "\n",
      "juliet:\n",
      "thou hast tell thee comes of a death here\n",
      "hath so hear it be steal this death,\n",
      "and the second i thou shalt me the penit\n",
      "and fearful will not in this soul would not here\n",
      "will be may dost the long his speak is show.\n",
      "\n",
      "friar laurence:\n",
      "i will a sullain! weak the world of the world:\n",
      "and i wom the mans, this warms and stay \n",
      "----------- Epoch 5/6 -----------\n",
      "Seed: condemned and myself excused.\n",
      "\n",
      "prince:\n",
      "t\n",
      "Result: condemned and myself excused.\n",
      "\n",
      "prince:\n",
      "then thy life that some away this now in the sea\n",
      "the street and wife the face that the chear,\n",
      "i'll doth me at our love, trues with the face.\n",
      "\n",
      "friar laurence:\n",
      "i wall some watchsed and heaven here's low.\n",
      "\n",
      "friar laurence:\n",
      "holy this heart, and there adist is the child;\n",
      "i will so means me and romeo, thou knows thou wilt with the prince,\n",
      "and there is the death thee to my child,\n",
      "that shall faith, and death is the romeo,\n",
      "and thou know but as i this heaven me their lies\n",
      "at honour that shame thee at death is some all,\n",
      "and said her, death to this this more took.\n",
      "\n",
      "balthasar:\n",
      "go with him at grief and not some streak\n",
      "to the sinter of death come as sweet how\n",
      "is stretted to church my son to the montague thee!\n",
      "\n",
      "friar laurence:\n",
      "helly as you this would disposter's head.\n",
      "\n",
      "first pursout:\n",
      "and so the capulets cousin, and there is this long,\n",
      "with the most be longer faith stimpless,\n",
      "and keep no look out the heart of this speak.\n",
      "\n",
      "capulet:\n",
      "what since there, and this is the prince,\n",
      "and be the fair arms and leave m\n",
      "----------- Epoch 6/6 -----------\n",
      "Seed: condemned and myself excused.\n",
      "\n",
      "prince:\n",
      "t\n",
      "Result: condemned and myself excused.\n",
      "\n",
      "prince:\n",
      "then i spake thee for that hath here shall one\n",
      "the cheeks and some pray him of the fair\n",
      "the father sleep to child ready the montague;\n",
      "and we do not romeo! what should have not to blood,\n",
      "and we are the hours there is the great daughter\n",
      "to death do you that there we do galland,\n",
      "holds are with a montague, bid him juliet.\n",
      "\n",
      "friar laurence:\n",
      "hath to the stats to be the lights and paris'd.\n",
      "\n",
      "friar laurence:\n",
      "i will was this faith, and say the watch,\n",
      "and be sumper a doth many mandly sort\n",
      "of this ready thee thee, sir, what should be do stors!\n",
      "o same when a barth the manty as the day.\n",
      "\n",
      "peter:\n",
      "and so the world and the griefure for this dead?\n",
      "\n",
      "prince:\n",
      "my lord and forth be many breath, be will:\n",
      "but the duath with the mother dead with thee to see.\n",
      "\n",
      "friar laurence:\n",
      "what is the most remancence listed to see\n",
      "the is the great bark! what we have your head,\n",
      "and with a most more than a more is my lady!\n",
      "o lairs of the world: but lay with the world:\n",
      "i do see my soul with the night of faith be dead?\n",
      "\n",
      "friar lauren\n"
     ]
    }
   ],
   "source": [
    "train_data, target_data, unique_chars, len_unique_chars = featurize(data)\n",
    "run(train_data, target_data, unique_chars, len_unique_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
